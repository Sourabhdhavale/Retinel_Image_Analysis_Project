{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "016f11c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger, TensorBoard\n",
    "from tensorflow.keras.utils import CustomObjectScope\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(tf.test.is_built_with_cuda())\n",
    "\n",
    "##data.py\n",
    "##read the images\n",
    "\n",
    "imsize = 512       #image size\n",
    "bridge_layer = 512 # bridge layer fileters in U-NET \n",
    "num_filters = [32, 64, 128, 256] # Filters in U-net\n",
    "training = 1 # program should only carry out testting\n",
    "\n",
    "def load_data(path, split=0.1):\n",
    "    images = sorted(glob(os.path.join(path,\"./BCSS-master/images/*\")))\n",
    "    masks = sorted(glob(os.path.join(path,\"./BCSS-master/masks_tumor/*\")))\n",
    "\n",
    "    total_size = len(images)\n",
    "    valid_size = int(split * total_size)\n",
    "    test_size = int(split * total_size)\n",
    "\n",
    "    train_x, valid_x = train_test_split(images, test_size=valid_size, random_state=42)\n",
    "    train_y, valid_y = train_test_split(masks, test_size=valid_size, random_state=42)\n",
    "\n",
    "    train_x, test_x = train_test_split(train_x, test_size=test_size, random_state=42)\n",
    "    train_y, test_y = train_test_split(train_y, test_size=test_size, random_state=42)\n",
    "\n",
    "    return (train_x, train_y), (valid_x, valid_y), (test_x, test_y)\n",
    "\n",
    "def read_image(path):\n",
    "    path = path.decode()\n",
    "    x = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    x = cv2.resize(x,(imsize, imsize))\n",
    "    x = x/255.0\n",
    "    return x\n",
    "\n",
    "def read_image_test(path):\n",
    "    #path = path.decode()\n",
    "    x = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    x = cv2.resize(x,(imsize, imsize))\n",
    "    x = x/255.0\n",
    "    return x\n",
    "\n",
    "def read_mask(path):\n",
    "    path = path.decode()\n",
    "    x = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    x = cv2.resize(x, (imsize, imsize))\n",
    "    x = x/255.0\n",
    "#     x = np.expand_dims(x, axis=-1)\n",
    "    return x\n",
    "\n",
    "def read_mask_test(path):\n",
    "    #path = path.decode()\n",
    "    x = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    x = cv2.resize(x, (imsize, imsize))\n",
    "    x = x/255.0\n",
    "#     x = np.expand_dims(x, axis=-1)\n",
    "    return x\n",
    "\n",
    "def myfun(img):\n",
    "    img = np.squeeze(img)\n",
    "\n",
    "    return img\n",
    "\n",
    "def mask_parse(mask):\n",
    "    mask = np.squeeze(mask)\n",
    "    mask = [mask, mask, mask]\n",
    "    mask = np.transpose(mask, (1, 2, 0))\n",
    "    return mask\n",
    "\n",
    "def tf_parse(x, y):\n",
    "    def _parse(x, y):\n",
    "        x = read_image(x)\n",
    "        y = read_mask(y)\n",
    "        return x, y\n",
    "\n",
    "    x, y = tf.numpy_function(_parse, [x, y], [tf.float64, tf.float64])\n",
    "    x.set_shape([imsize, imsize, 3])\n",
    "    y.set_shape([imsize, imsize, 3])\n",
    "    return x, y\n",
    "\n",
    "def tf_dataset(x, y, batch=16):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "    dataset = dataset.map(tf_parse)\n",
    "    dataset = dataset.batch(batch)\n",
    "    dataset = dataset.repeat()\n",
    "    return dataset\n",
    "\n",
    "#model.py\n",
    "#building the u-net arch\n",
    "\n",
    "\n",
    "\n",
    "def conv_block(x, num_filters):\n",
    "    x = Conv2D(num_filters, (3, 3), padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    x = Conv2D(num_filters, (3, 3), padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def build_model():\n",
    "    size = imsize\n",
    "    \n",
    "    inputs = Input((size, size, 3))\n",
    "\n",
    "    skip_x = []\n",
    "    x = inputs\n",
    "    ## Encoder\n",
    "    for f in num_filters:\n",
    "        x = conv_block(x, f)\n",
    "        skip_x.append(x)\n",
    "        x = MaxPool2D((2, 2))(x)\n",
    "\n",
    "    ## Bridge\n",
    "    x = conv_block(x, bridge_layer)\n",
    "\n",
    "    num_filters.reverse()\n",
    "    skip_x.reverse()\n",
    "    ## Decoder\n",
    "    for i, f in enumerate(num_filters):\n",
    "        x = UpSampling2D((2, 2))(x)\n",
    "        xs = skip_x[i]\n",
    "        x = Concatenate()([x, xs])\n",
    "        x = conv_block(x, f)\n",
    "\n",
    "    ## Output\n",
    "    x = Conv2D(3, (3, 3), padding=\"same\")(x)\n",
    "    x = Activation(\"sigmoid\")(x)\n",
    "    return Model(inputs, x)\n",
    "\n",
    "##Train.py\n",
    "\n",
    "\n",
    "\n",
    "def iou(y_true, y_pred):\n",
    "    def f(y_true, y_pred):\n",
    "        intersection = (y_true * y_pred).sum()\n",
    "        union = y_true.sum() + y_pred.sum() - intersection\n",
    "        x = (intersection + 1e-15) / (union + 1e-15)\n",
    "        x = x.astype(np.float32)\n",
    "        return x\n",
    "    \n",
    "    return tf.numpy_function(f, [y_true, y_pred], tf.float32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e30ff110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Buid....\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 512, 512, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 512, 512, 32) 896         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 512, 512, 32) 128         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 512, 512, 32) 0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 512, 512, 32) 9248        activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 512, 512, 32) 128         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 512, 512, 32) 0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling2D) (None, 256, 256, 32) 0           activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 256, 256, 64) 18496       max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 256, 256, 64) 256         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 256, 256, 64) 0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 256, 256, 64) 36928       activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 256, 256, 64) 256         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 256, 256, 64) 0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling2D) (None, 128, 128, 64) 0           activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 128, 128, 128 73856       max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 128, 128, 128 512         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 128, 128, 128 0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 128, 128, 128 147584      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 128, 128, 128 512         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 128, 128, 128 0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling2D) (None, 64, 64, 128)  0           activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 64, 64, 256)  295168      max_pooling2d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 64, 64, 256)  1024        conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 64, 64, 256)  0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 64, 64, 256)  590080      activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 64, 64, 256)  1024        conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 64, 64, 256)  0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling2D) (None, 32, 32, 256)  0           activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 32, 32, 512)  1180160     max_pooling2d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 32, 32, 512)  2048        conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 32, 32, 512)  0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 32, 32, 512)  2359808     activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 32, 32, 512)  2048        conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 32, 32, 512)  0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_12 (UpSampling2D) (None, 64, 64, 512)  0           activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 64, 64, 768)  0           up_sampling2d_12[0][0]           \n",
      "                                                                 activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 64, 64, 256)  1769728     concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 64, 64, 256)  1024        conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 64, 64, 256)  0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 64, 64, 256)  590080      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 64, 64, 256)  1024        conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 64, 64, 256)  0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_13 (UpSampling2D) (None, 128, 128, 256 0           activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 128, 128, 384 0           up_sampling2d_13[0][0]           \n",
      "                                                                 activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 128, 128, 128 442496      concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 128, 128, 128 512         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 128, 128, 128 0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 128, 128, 128 147584      activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 128, 128, 128 512         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 128, 128, 128 0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_14 (UpSampling2D) (None, 256, 256, 128 0           activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 256, 256, 192 0           up_sampling2d_14[0][0]           \n",
      "                                                                 activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 256, 256, 64) 110656      concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 256, 256, 64) 256         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 256, 256, 64) 0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 256, 256, 64) 36928       activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 256, 256, 64) 256         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 256, 256, 64) 0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_15 (UpSampling2D) (None, 512, 512, 64) 0           activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 512, 512, 96) 0           up_sampling2d_15[0][0]           \n",
      "                                                                 activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 512, 512, 32) 27680       concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 512, 512, 32) 128         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 512, 512, 32) 0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 512, 512, 32) 9248        activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 512, 512, 32) 128         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 512, 512, 32) 0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 512, 512, 3)  867         activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 512, 512, 3)  0           conv2d_75[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 7,859,267\n",
      "Trainable params: 7,853,379\n",
      "Non-trainable params: 5,888\n",
      "__________________________________________________________________________________________________\n",
      "Training ....\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 121s 2s/step - loss: 0.0090 - acc: 0.7334 - recall_3: 0.2350 - precision_3: 0.9996 - iou: 0.3645 - val_loss: 0.0793 - val_acc: 0.8397 - val_recall_3: 0.2846 - val_precision_3: 0.9896 - val_iou: 0.3459\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0039 - acc: 0.8034 - recall_3: 0.2230 - precision_3: 1.0000 - iou: 0.3720 - val_loss: 0.0509 - val_acc: 0.8397 - val_recall_3: 0.3207 - val_precision_3: 0.9877 - val_iou: 0.3196\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0034 - acc: 0.8391 - recall_3: 0.2221 - precision_3: 1.0000 - iou: 0.3726 - val_loss: 0.0510 - val_acc: 0.8397 - val_recall_3: 0.3337 - val_precision_3: 0.9882 - val_iou: 0.3083\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0032 - acc: 0.8358 - recall_3: 0.2231 - precision_3: 1.0000 - iou: 0.3728 - val_loss: 0.0452 - val_acc: 0.8397 - val_recall_3: 0.3090 - val_precision_3: 0.9877 - val_iou: 0.3058\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0030 - acc: 0.8396 - recall_3: 0.2234 - precision_3: 1.0000 - iou: 0.3732 - val_loss: 0.0641 - val_acc: 0.8397 - val_recall_3: 0.3283 - val_precision_3: 0.9889 - val_iou: 0.2882\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0028 - acc: 0.8396 - recall_3: 0.2227 - precision_3: 1.0000 - iou: 0.3736 - val_loss: 0.0389 - val_acc: 0.8397 - val_recall_3: 0.2717 - val_precision_3: 0.9985 - val_iou: 0.3047\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0027 - acc: 0.8406 - recall_3: 0.2227 - precision_3: 1.0000 - iou: 0.3738 - val_loss: 0.0208 - val_acc: 0.8397 - val_recall_3: 0.2416 - val_precision_3: 1.0000 - val_iou: 0.3285\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0025 - acc: 0.8401 - recall_3: 0.2233 - precision_3: 1.0000 - iou: 0.3744 - val_loss: 0.0104 - val_acc: 0.8397 - val_recall_3: 0.2300 - val_precision_3: 1.0000 - val_iou: 0.3467\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0024 - acc: 0.8356 - recall_3: 0.2251 - precision_3: 1.0000 - iou: 0.3747 - val_loss: 0.0048 - val_acc: 0.8397 - val_recall_3: 0.2223 - val_precision_3: 1.0000 - val_iou: 0.3587\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0023 - acc: 0.8352 - recall_3: 0.2254 - precision_3: 1.0000 - iou: 0.3747 - val_loss: 0.0031 - val_acc: 0.8397 - val_recall_3: 0.2153 - val_precision_3: 1.0000 - val_iou: 0.3679\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0023 - acc: 0.8330 - recall_3: 0.2261 - precision_3: 1.0000 - iou: 0.3750 - val_loss: 0.0024 - val_acc: 0.8397 - val_recall_3: 0.2138 - val_precision_3: 1.0000 - val_iou: 0.3728\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0022 - acc: 0.8373 - recall_3: 0.2266 - precision_3: 1.0000 - iou: 0.3751 - val_loss: 0.0020 - val_acc: 0.8394 - val_recall_3: 0.2203 - val_precision_3: 1.0000 - val_iou: 0.3785\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0021 - acc: 0.8366 - recall_3: 0.2278 - precision_3: 1.0000 - iou: 0.3753 - val_loss: 0.0021 - val_acc: 0.8387 - val_recall_3: 0.2744 - val_precision_3: 1.0000 - val_iou: 0.3885\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0020 - acc: 0.8368 - recall_3: 0.2277 - precision_3: 1.0000 - iou: 0.3755 - val_loss: 0.0043 - val_acc: 0.8378 - val_recall_3: 0.2286 - val_precision_3: 1.0000 - val_iou: 0.3771\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0019 - acc: 0.8403 - recall_3: 0.2267 - precision_3: 1.0000 - iou: 0.3756 - val_loss: 0.0019 - val_acc: 0.8356 - val_recall_3: 0.2479 - val_precision_3: 1.0000 - val_iou: 0.3878\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0019 - acc: 0.8370 - recall_3: 0.2262 - precision_3: 1.0000 - iou: 0.3759 - val_loss: 0.0054 - val_acc: 0.8287 - val_recall_3: 0.2928 - val_precision_3: 1.0000 - val_iou: 0.4076\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0015 - acc: 0.8460 - recall_3: 0.2241 - precision_3: 1.0000 - iou: 0.3758 - val_loss: 0.0013 - val_acc: 0.8407 - val_recall_3: 0.2406 - val_precision_3: 1.0000 - val_iou: 0.3950\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0014 - acc: 0.8406 - recall_3: 0.2242 - precision_3: 1.0000 - iou: 0.3762 - val_loss: 0.0011 - val_acc: 0.8388 - val_recall_3: 0.2337 - val_precision_3: 1.0000 - val_iou: 0.3912\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0014 - acc: 0.8395 - recall_3: 0.2246 - precision_3: 1.0000 - iou: 0.3762 - val_loss: 0.0011 - val_acc: 0.8389 - val_recall_3: 0.2314 - val_precision_3: 1.0000 - val_iou: 0.3894\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0014 - acc: 0.8395 - recall_3: 0.2246 - precision_3: 1.0000 - iou: 0.3763 - val_loss: 0.0011 - val_acc: 0.8391 - val_recall_3: 0.2306 - val_precision_3: 1.0000 - val_iou: 0.3884\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0013 - acc: 0.8397 - recall_3: 0.2245 - precision_3: 1.0000 - iou: 0.3764 - val_loss: 0.0011 - val_acc: 0.8393 - val_recall_3: 0.2301 - val_precision_3: 1.0000 - val_iou: 0.3878\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0013 - acc: 0.8399 - recall_3: 0.2244 - precision_3: 1.0000 - iou: 0.3765 - val_loss: 0.0011 - val_acc: 0.8397 - val_recall_3: 0.2300 - val_precision_3: 1.0000 - val_iou: 0.3877\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0012 - acc: 0.8398 - recall_3: 0.2219 - precision_3: 1.0000 - iou: 0.3758 - val_loss: 0.0011 - val_acc: 0.8396 - val_recall_3: 0.2328 - val_precision_3: 1.0000 - val_iou: 0.3882\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0012 - acc: 0.8401 - recall_3: 0.2235 - precision_3: 1.0000 - iou: 0.3763 - val_loss: 0.0010 - val_acc: 0.8395 - val_recall_3: 0.2333 - val_precision_3: 1.0000 - val_iou: 0.3887\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0012 - acc: 0.8401 - recall_3: 0.2240 - precision_3: 1.0000 - iou: 0.3765 - val_loss: 0.0010 - val_acc: 0.8395 - val_recall_3: 0.2334 - val_precision_3: 1.0000 - val_iou: 0.3890\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0012 - acc: 0.8400 - recall_3: 0.2241 - precision_3: 1.0000 - iou: 0.3765 - val_loss: 9.9594e-04 - val_acc: 0.8395 - val_recall_3: 0.2335 - val_precision_3: 1.0000 - val_iou: 0.3893\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0012 - acc: 0.8399 - recall_3: 0.2241 - precision_3: 1.0000 - iou: 0.3765 - val_loss: 9.8926e-04 - val_acc: 0.8394 - val_recall_3: 0.2336 - val_precision_3: 1.0000 - val_iou: 0.3894\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0012 - acc: 0.8398 - recall_3: 0.2242 - precision_3: 1.0000 - iou: 0.3765 - val_loss: 9.8462e-04 - val_acc: 0.8392 - val_recall_3: 0.2337 - val_precision_3: 1.0000 - val_iou: 0.3896\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0012 - acc: 0.8398 - recall_3: 0.2241 - precision_3: 1.0000 - iou: 0.3765 - val_loss: 9.8056e-04 - val_acc: 0.8392 - val_recall_3: 0.2335 - val_precision_3: 1.0000 - val_iou: 0.3896\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0012 - acc: 0.8398 - recall_3: 0.2241 - precision_3: 1.0000 - iou: 0.3765 - val_loss: 9.7839e-04 - val_acc: 0.8392 - val_recall_3: 0.2334 - val_precision_3: 1.0000 - val_iou: 0.3897\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0012 - acc: 0.8398 - recall_3: 0.2241 - precision_3: 1.0000 - iou: 0.3765 - val_loss: 9.7708e-04 - val_acc: 0.8391 - val_recall_3: 0.2334 - val_precision_3: 1.0000 - val_iou: 0.3897\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0012 - acc: 0.8398 - recall_3: 0.2241 - precision_3: 1.0000 - iou: 0.3765 - val_loss: 9.7620e-04 - val_acc: 0.8391 - val_recall_3: 0.2333 - val_precision_3: 1.0000 - val_iou: 0.3897\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0012 - acc: 0.8398 - recall_3: 0.2241 - precision_3: 1.0000 - iou: 0.3765 - val_loss: 9.7575e-04 - val_acc: 0.8391 - val_recall_3: 0.2333 - val_precision_3: 1.0000 - val_iou: 0.3898\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0012 - acc: 0.8398 - recall_3: 0.2241 - precision_3: 1.0000 - iou: 0.3765 - val_loss: 9.7549e-04 - val_acc: 0.8391 - val_recall_3: 0.2333 - val_precision_3: 1.0000 - val_iou: 0.3898\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0012 - acc: 0.8398 - recall_3: 0.2241 - precision_3: 1.0000 - iou: 0.3765 - val_loss: 9.7532e-04 - val_acc: 0.8390 - val_recall_3: 0.2333 - val_precision_3: 1.0000 - val_iou: 0.3898\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0012 - acc: 0.8398 - recall_3: 0.2241 - precision_3: 1.0000 - iou: 0.3765 - val_loss: 9.7521e-04 - val_acc: 0.8390 - val_recall_3: 0.2333 - val_precision_3: 1.0000 - val_iou: 0.3898\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0012 - acc: 0.8398 - recall_3: 0.2241 - precision_3: 1.0000 - iou: 0.3765 - val_loss: 9.7515e-04 - val_acc: 0.8390 - val_recall_3: 0.2333 - val_precision_3: 1.0000 - val_iou: 0.3898\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0012 - acc: 0.8398 - recall_3: 0.2241 - precision_3: 1.0000 - iou: 0.3765 - val_loss: 9.7511e-04 - val_acc: 0.8390 - val_recall_3: 0.2333 - val_precision_3: 1.0000 - val_iou: 0.3898\n",
      "Epoch 39/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0012 - acc: 0.8398 - recall_3: 0.2241 - precision_3: 1.0000 - iou: 0.3765 - val_loss: 9.7509e-04 - val_acc: 0.8390 - val_recall_3: 0.2333 - val_precision_3: 1.0000 - val_iou: 0.3898\n",
      "Epoch 40/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0012 - acc: 0.8398 - recall_3: 0.2241 - precision_3: 1.0000 - iou: 0.3765 - val_loss: 9.7507e-04 - val_acc: 0.8390 - val_recall_3: 0.2333 - val_precision_3: 1.0000 - val_iou: 0.3898\n",
      "Epoch 41/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0012 - acc: 0.8398 - recall_3: 0.2241 - precision_3: 1.0000 - iou: 0.3765 - val_loss: 9.7506e-04 - val_acc: 0.8390 - val_recall_3: 0.2333 - val_precision_3: 1.0000 - val_iou: 0.3898\n",
      "Epoch 42/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0012 - acc: 0.8398 - recall_3: 0.2241 - precision_3: 1.0000 - iou: 0.3765 - val_loss: 9.7506e-04 - val_acc: 0.8390 - val_recall_3: 0.2333 - val_precision_3: 1.0000 - val_iou: 0.3898\n",
      "Epoch 43/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0012 - acc: 0.8398 - recall_3: 0.2241 - precision_3: 1.0000 - iou: 0.3765 - val_loss: 9.7506e-04 - val_acc: 0.8390 - val_recall_3: 0.2333 - val_precision_3: 1.0000 - val_iou: 0.3898\n",
      "Epoch 44/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0012 - acc: 0.8398 - recall_3: 0.2241 - precision_3: 1.0000 - iou: 0.3765 - val_loss: 9.7505e-04 - val_acc: 0.8390 - val_recall_3: 0.2333 - val_precision_3: 1.0000 - val_iou: 0.3898\n",
      "Epoch 45/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0012 - acc: 0.8398 - recall_3: 0.2241 - precision_3: 1.0000 - iou: 0.3765 - val_loss: 9.7505e-04 - val_acc: 0.8390 - val_recall_3: 0.2333 - val_precision_3: 1.0000 - val_iou: 0.3898\n",
      "Epoch 46/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0012 - acc: 0.8398 - recall_3: 0.2241 - precision_3: 1.0000 - iou: 0.3765 - val_loss: 9.7505e-04 - val_acc: 0.8390 - val_recall_3: 0.2333 - val_precision_3: 1.0000 - val_iou: 0.3898\n",
      "Epoch 47/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0012 - acc: 0.8398 - recall_3: 0.2241 - precision_3: 1.0000 - iou: 0.3765 - val_loss: 9.7505e-04 - val_acc: 0.8390 - val_recall_3: 0.2333 - val_precision_3: 1.0000 - val_iou: 0.3898\n",
      "Epoch 48/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0012 - acc: 0.8398 - recall_3: 0.2241 - precision_3: 1.0000 - iou: 0.3765 - val_loss: 9.7505e-04 - val_acc: 0.8390 - val_recall_3: 0.2333 - val_precision_3: 1.0000 - val_iou: 0.3898\n",
      "Epoch 49/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0012 - acc: 0.8398 - recall_3: 0.2241 - precision_3: 1.0000 - iou: 0.3765 - val_loss: 9.7505e-04 - val_acc: 0.8390 - val_recall_3: 0.2333 - val_precision_3: 1.0000 - val_iou: 0.3898\n",
      "Epoch 50/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0012 - acc: 0.8398 - recall_3: 0.2241 - precision_3: 1.0000 - iou: 0.3765 - val_loss: 9.7505e-04 - val_acc: 0.8390 - val_recall_3: 0.2333 - val_precision_3: 1.0000 - val_iou: 0.3898\n",
      "Epoch 51/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0012 - acc: 0.8398 - recall_3: 0.2241 - precision_3: 1.0000 - iou: 0.3765 - val_loss: 9.7505e-04 - val_acc: 0.8390 - val_recall_3: 0.2333 - val_precision_3: 1.0000 - val_iou: 0.3898\n",
      "Epoch 52/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0012 - acc: 0.8398 - recall_3: 0.2241 - precision_3: 1.0000 - iou: 0.3765 - val_loss: 9.7505e-04 - val_acc: 0.8390 - val_recall_3: 0.2333 - val_precision_3: 1.0000 - val_iou: 0.3898\n",
      "Epoch 53/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0012 - acc: 0.8398 - recall_3: 0.2241 - precision_3: 1.0000 - iou: 0.3765 - val_loss: 9.7505e-04 - val_acc: 0.8390 - val_recall_3: 0.2333 - val_precision_3: 1.0000 - val_iou: 0.3898\n",
      "Epoch 54/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0012 - acc: 0.8398 - recall_3: 0.2241 - precision_3: 1.0000 - iou: 0.3765 - val_loss: 9.7505e-04 - val_acc: 0.8390 - val_recall_3: 0.2333 - val_precision_3: 1.0000 - val_iou: 0.3898\n",
      "Epoch 55/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0012 - acc: 0.8398 - recall_3: 0.2241 - precision_3: 1.0000 - iou: 0.3765 - val_loss: 9.7505e-04 - val_acc: 0.8390 - val_recall_3: 0.2333 - val_precision_3: 1.0000 - val_iou: 0.3898\n",
      "Epoch 56/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0012 - acc: 0.8398 - recall_3: 0.2241 - precision_3: 1.0000 - iou: 0.3765 - val_loss: 9.7505e-04 - val_acc: 0.8390 - val_recall_3: 0.2333 - val_precision_3: 1.0000 - val_iou: 0.3898\n",
      "Epoch 57/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0012 - acc: 0.8398 - recall_3: 0.2241 - precision_3: 1.0000 - iou: 0.3765 - val_loss: 9.7505e-04 - val_acc: 0.8390 - val_recall_3: 0.2333 - val_precision_3: 1.0000 - val_iou: 0.3898\n",
      "Epoch 58/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0012 - acc: 0.8398 - recall_3: 0.2241 - precision_3: 1.0000 - iou: 0.3765 - val_loss: 9.7505e-04 - val_acc: 0.8390 - val_recall_3: 0.2333 - val_precision_3: 1.0000 - val_iou: 0.3898\n",
      "Epoch 59/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0012 - acc: 0.8398 - recall_3: 0.2241 - precision_3: 1.0000 - iou: 0.3765 - val_loss: 9.7505e-04 - val_acc: 0.8390 - val_recall_3: 0.2333 - val_precision_3: 1.0000 - val_iou: 0.3898\n",
      "Epoch 60/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0012 - acc: 0.8398 - recall_3: 0.2241 - precision_3: 1.0000 - iou: 0.3765 - val_loss: 9.7505e-04 - val_acc: 0.8390 - val_recall_3: 0.2333 - val_precision_3: 1.0000 - val_iou: 0.3898\n",
      "Epoch 61/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0012 - acc: 0.8398 - recall_3: 0.2241 - precision_3: 1.0000 - iou: 0.3765 - val_loss: 9.7505e-04 - val_acc: 0.8390 - val_recall_3: 0.2333 - val_precision_3: 1.0000 - val_iou: 0.3898\n",
      "Epoch 62/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0012 - acc: 0.8398 - recall_3: 0.2241 - precision_3: 1.0000 - iou: 0.3765 - val_loss: 9.7505e-04 - val_acc: 0.8390 - val_recall_3: 0.2333 - val_precision_3: 1.0000 - val_iou: 0.3898\n",
      "Epoch 63/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0012 - acc: 0.8398 - recall_3: 0.2241 - precision_3: 1.0000 - iou: 0.3765 - val_loss: 9.7505e-04 - val_acc: 0.8390 - val_recall_3: 0.2333 - val_precision_3: 1.0000 - val_iou: 0.3898\n",
      "Epoch 64/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0012 - acc: 0.8398 - recall_3: 0.2241 - precision_3: 1.0000 - iou: 0.3765 - val_loss: 9.7505e-04 - val_acc: 0.8390 - val_recall_3: 0.2333 - val_precision_3: 1.0000 - val_iou: 0.3898\n",
      "Epoch 65/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0012 - acc: 0.8398 - recall_3: 0.2241 - precision_3: 1.0000 - iou: 0.3765 - val_loss: 9.7505e-04 - val_acc: 0.8390 - val_recall_3: 0.2333 - val_precision_3: 1.0000 - val_iou: 0.3898\n",
      "Epoch 66/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0012 - acc: 0.8398 - recall_3: 0.2241 - precision_3: 1.0000 - iou: 0.3765 - val_loss: 9.7505e-04 - val_acc: 0.8390 - val_recall_3: 0.2333 - val_precision_3: 1.0000 - val_iou: 0.3898\n",
      "Epoch 67/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0012 - acc: 0.8398 - recall_3: 0.2241 - precision_3: 1.0000 - iou: 0.3765 - val_loss: 9.7505e-04 - val_acc: 0.8390 - val_recall_3: 0.2333 - val_precision_3: 1.0000 - val_iou: 0.3898\n",
      "Epoch 68/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0012 - acc: 0.8398 - recall_3: 0.2241 - precision_3: 1.0000 - iou: 0.3765 - val_loss: 9.7505e-04 - val_acc: 0.8390 - val_recall_3: 0.2333 - val_precision_3: 1.0000 - val_iou: 0.3898\n",
      "Epoch 69/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0012 - acc: 0.8398 - recall_3: 0.2241 - precision_3: 1.0000 - iou: 0.3765 - val_loss: 9.7505e-04 - val_acc: 0.8390 - val_recall_3: 0.2333 - val_precision_3: 1.0000 - val_iou: 0.3898\n",
      "Epoch 70/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0012 - acc: 0.8398 - recall_3: 0.2241 - precision_3: 1.0000 - iou: 0.3765 - val_loss: 9.7505e-04 - val_acc: 0.8390 - val_recall_3: 0.2333 - val_precision_3: 1.0000 - val_iou: 0.3898\n",
      "Epoch 71/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0012 - acc: 0.8398 - recall_3: 0.2241 - precision_3: 1.0000 - iou: 0.3765 - val_loss: 9.7505e-04 - val_acc: 0.8390 - val_recall_3: 0.2333 - val_precision_3: 1.0000 - val_iou: 0.3898\n",
      "Epoch 72/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0012 - acc: 0.8398 - recall_3: 0.2241 - precision_3: 1.0000 - iou: 0.3765 - val_loss: 9.7505e-04 - val_acc: 0.8390 - val_recall_3: 0.2333 - val_precision_3: 1.0000 - val_iou: 0.3898\n",
      "Epoch 73/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0012 - acc: 0.8398 - recall_3: 0.2241 - precision_3: 1.0000 - iou: 0.3765 - val_loss: 9.7505e-04 - val_acc: 0.8390 - val_recall_3: 0.2333 - val_precision_3: 1.0000 - val_iou: 0.3898\n",
      "Epoch 74/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0012 - acc: 0.8398 - recall_3: 0.2241 - precision_3: 1.0000 - iou: 0.3765 - val_loss: 9.7505e-04 - val_acc: 0.8390 - val_recall_3: 0.2333 - val_precision_3: 1.0000 - val_iou: 0.3898\n",
      "Epoch 75/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0012 - acc: 0.8398 - recall_3: 0.2241 - precision_3: 1.0000 - iou: 0.3765 - val_loss: 9.7505e-04 - val_acc: 0.8390 - val_recall_3: 0.2333 - val_precision_3: 1.0000 - val_iou: 0.3898\n",
      "Epoch 76/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0012 - acc: 0.8398 - recall_3: 0.2241 - precision_3: 1.0000 - iou: 0.3765 - val_loss: 9.7505e-04 - val_acc: 0.8390 - val_recall_3: 0.2333 - val_precision_3: 1.0000 - val_iou: 0.3898\n",
      "Epoch 77/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0012 - acc: 0.8398 - recall_3: 0.2241 - precision_3: 1.0000 - iou: 0.3765 - val_loss: 9.7505e-04 - val_acc: 0.8390 - val_recall_3: 0.2333 - val_precision_3: 1.0000 - val_iou: 0.3898\n",
      "Epoch 78/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0012 - acc: 0.8398 - recall_3: 0.2241 - precision_3: 1.0000 - iou: 0.3765 - val_loss: 9.7505e-04 - val_acc: 0.8390 - val_recall_3: 0.2333 - val_precision_3: 1.0000 - val_iou: 0.3898\n",
      "Epoch 79/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0012 - acc: 0.8398 - recall_3: 0.2241 - precision_3: 1.0000 - iou: 0.3765 - val_loss: 9.7505e-04 - val_acc: 0.8390 - val_recall_3: 0.2333 - val_precision_3: 1.0000 - val_iou: 0.3898\n",
      "Epoch 80/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0012 - acc: 0.8398 - recall_3: 0.2241 - precision_3: 1.0000 - iou: 0.3765 - val_loss: 9.7505e-04 - val_acc: 0.8390 - val_recall_3: 0.2333 - val_precision_3: 1.0000 - val_iou: 0.3898\n",
      "Epoch 81/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0012 - acc: 0.8398 - recall_3: 0.2241 - precision_3: 1.0000 - iou: 0.3765 - val_loss: 9.7505e-04 - val_acc: 0.8390 - val_recall_3: 0.2333 - val_precision_3: 1.0000 - val_iou: 0.3898\n",
      "Epoch 82/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0012 - acc: 0.8398 - recall_3: 0.2241 - precision_3: 1.0000 - iou: 0.3765 - val_loss: 9.7505e-04 - val_acc: 0.8390 - val_recall_3: 0.2333 - val_precision_3: 1.0000 - val_iou: 0.3898\n",
      "Epoch 83/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0012 - acc: 0.8398 - recall_3: 0.2241 - precision_3: 1.0000 - iou: 0.3765 - val_loss: 9.7505e-04 - val_acc: 0.8390 - val_recall_3: 0.2333 - val_precision_3: 1.0000 - val_iou: 0.3898\n",
      "Epoch 84/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0012 - acc: 0.8398 - recall_3: 0.2241 - precision_3: 1.0000 - iou: 0.3765 - val_loss: 9.7505e-04 - val_acc: 0.8390 - val_recall_3: 0.2333 - val_precision_3: 1.0000 - val_iou: 0.3898\n",
      "Epoch 85/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0012 - acc: 0.8398 - recall_3: 0.2241 - precision_3: 1.0000 - iou: 0.3765 - val_loss: 9.7505e-04 - val_acc: 0.8390 - val_recall_3: 0.2333 - val_precision_3: 1.0000 - val_iou: 0.3898\n",
      "Epoch 86/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0012 - acc: 0.8398 - recall_3: 0.2241 - precision_3: 1.0000 - iou: 0.3765 - val_loss: 9.7505e-04 - val_acc: 0.8390 - val_recall_3: 0.2333 - val_precision_3: 1.0000 - val_iou: 0.3898\n",
      "Epoch 87/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0012 - acc: 0.8398 - recall_3: 0.2241 - precision_3: 1.0000 - iou: 0.3765 - val_loss: 9.7505e-04 - val_acc: 0.8390 - val_recall_3: 0.2333 - val_precision_3: 1.0000 - val_iou: 0.3898\n",
      "Epoch 88/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0012 - acc: 0.8398 - recall_3: 0.2241 - precision_3: 1.0000 - iou: 0.3765 - val_loss: 9.7505e-04 - val_acc: 0.8390 - val_recall_3: 0.2333 - val_precision_3: 1.0000 - val_iou: 0.3898\n",
      "Epoch 89/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0012 - acc: 0.8398 - recall_3: 0.2241 - precision_3: 1.0000 - iou: 0.3765 - val_loss: 9.7505e-04 - val_acc: 0.8390 - val_recall_3: 0.2333 - val_precision_3: 1.0000 - val_iou: 0.3898\n",
      "Epoch 90/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0012 - acc: 0.8398 - recall_3: 0.2241 - precision_3: 1.0000 - iou: 0.3765 - val_loss: 9.7505e-04 - val_acc: 0.8390 - val_recall_3: 0.2333 - val_precision_3: 1.0000 - val_iou: 0.3898\n",
      "Epoch 91/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0012 - acc: 0.8398 - recall_3: 0.2241 - precision_3: 1.0000 - iou: 0.3765 - val_loss: 9.7505e-04 - val_acc: 0.8390 - val_recall_3: 0.2333 - val_precision_3: 1.0000 - val_iou: 0.3898\n",
      "Epoch 92/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0012 - acc: 0.8398 - recall_3: 0.2241 - precision_3: 1.0000 - iou: 0.3765 - val_loss: 9.7505e-04 - val_acc: 0.8390 - val_recall_3: 0.2333 - val_precision_3: 1.0000 - val_iou: 0.3898\n",
      "Epoch 93/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0012 - acc: 0.8398 - recall_3: 0.2241 - precision_3: 1.0000 - iou: 0.3765 - val_loss: 9.7505e-04 - val_acc: 0.8390 - val_recall_3: 0.2333 - val_precision_3: 1.0000 - val_iou: 0.3898\n",
      "Epoch 94/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0012 - acc: 0.8398 - recall_3: 0.2241 - precision_3: 1.0000 - iou: 0.3765 - val_loss: 9.7505e-04 - val_acc: 0.8390 - val_recall_3: 0.2333 - val_precision_3: 1.0000 - val_iou: 0.3898\n",
      "Epoch 95/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0012 - acc: 0.8398 - recall_3: 0.2241 - precision_3: 1.0000 - iou: 0.3765 - val_loss: 9.7505e-04 - val_acc: 0.8390 - val_recall_3: 0.2333 - val_precision_3: 1.0000 - val_iou: 0.3898\n",
      "Epoch 96/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0012 - acc: 0.8398 - recall_3: 0.2241 - precision_3: 1.0000 - iou: 0.3765 - val_loss: 9.7505e-04 - val_acc: 0.8390 - val_recall_3: 0.2333 - val_precision_3: 1.0000 - val_iou: 0.3898\n",
      "Epoch 97/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0012 - acc: 0.8398 - recall_3: 0.2241 - precision_3: 1.0000 - iou: 0.3765 - val_loss: 9.7505e-04 - val_acc: 0.8390 - val_recall_3: 0.2333 - val_precision_3: 1.0000 - val_iou: 0.3898\n",
      "Epoch 98/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0012 - acc: 0.8398 - recall_3: 0.2241 - precision_3: 1.0000 - iou: 0.3765 - val_loss: 9.7505e-04 - val_acc: 0.8390 - val_recall_3: 0.2333 - val_precision_3: 1.0000 - val_iou: 0.3898\n",
      "Epoch 99/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0012 - acc: 0.8398 - recall_3: 0.2241 - precision_3: 1.0000 - iou: 0.3765 - val_loss: 9.7505e-04 - val_acc: 0.8390 - val_recall_3: 0.2333 - val_precision_3: 1.0000 - val_iou: 0.3898\n",
      "Epoch 100/100\n",
      "48/48 [==============================] - 117s 2s/step - loss: 0.0012 - acc: 0.8398 - recall_3: 0.2241 - precision_3: 1.0000 - iou: 0.3765 - val_loss: 9.7505e-04 - val_acc: 0.8390 - val_recall_3: 0.2333 - val_precision_3: 1.0000 - val_iou: 0.3898\n",
      "Evaluating model\n",
      "\n",
      "6/6 [==============================] - 6s 920ms/step - loss: 8.7770e-04 - acc: 0.8426 - recall_3: 0.2260 - precision_3: 1.0000 - iou: 0.3818\n",
      "Evaluating model ... complete\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 48/48 [00:11<00:00,  4.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    ## Dataset\n",
    "   # np.random.seed(42);\n",
    "  #np.random.set_seed(42);\n",
    "    #os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "    #config = tf.compat.v1.ConfigProto()\n",
    "    #config.gpu_options.allow_growth = True\n",
    "    #config = tf.compat.v1.ConfigProto(device_count={'GPU': 0})\n",
    "    #sess = tf.compat.v1.Session(config=config)\n",
    "    path = \".\"\n",
    "    (train_x, train_y), (valid_x, valid_y), (test_x, test_y) = load_data(path)\n",
    "\n",
    "    ## Hyperparameters\n",
    "    batch = 8\n",
    "    lr = 1e-3\n",
    "    epochs = 100\n",
    "\n",
    "    train_dataset = tf_dataset(train_x, train_y, batch=batch)\n",
    "    valid_dataset = tf_dataset(valid_x, valid_y, batch=batch)\n",
    "    test_dataset = tf_dataset(test_x, test_y, batch=batch)\n",
    "\n",
    "    if os.path.isfile(\"./BCSS-master/files/model.h5\"):\n",
    "        with CustomObjectScope({'iou': iou}):\n",
    "            model = tf.keras.models.load_model(\"./BCSS-master/files/model.h5\")\n",
    "    else:\n",
    "        model = build_model()\t\t\n",
    "    print(\"Model Buid....\")\n",
    "    model.summary()\n",
    "    \n",
    "    opt = tf.keras.optimizers.Adam(lr)\n",
    "    metrics = [\"acc\", tf.keras.metrics.Recall(), tf.keras.metrics.Precision(), iou]\n",
    "    model.compile(loss=\"mse\", optimizer=opt, metrics=metrics)\n",
    "\n",
    "    callbacks = [\n",
    "        ModelCheckpoint(\"./BCSS-master/files/model.h5\"),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=4),\n",
    "        CSVLogger(\"./BCSS-master/files/data.csv\"),\n",
    "        TensorBoard(),\n",
    "        #EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=False)\n",
    "    ]\n",
    "\n",
    "    train_steps = len(train_x)//batch\n",
    "    valid_steps = len(valid_x)//batch\n",
    "    test_steps = len(test_x)//batch\n",
    "    if len(train_x) % batch != 0:\n",
    "        train_steps += 1\n",
    "    if len(valid_x) % batch != 0:\n",
    "        valid_steps += 1\n",
    "    if len(test_x) % batch != 0:\n",
    "        test_steps += 1  \n",
    "    print(\"Training ....\")\n",
    "#     print(train_dataset)\n",
    "#     print(valid_dataset)\n",
    "#     print(train_steps)\n",
    "#     print(valid_steps)\n",
    "#     print(callbacks)\n",
    "    if training == 1:\n",
    "        model.fit(train_dataset,\n",
    "            validation_data=valid_dataset,\n",
    "            epochs=epochs,\n",
    "            steps_per_epoch=train_steps,\n",
    "            validation_steps=valid_steps,\n",
    "            callbacks=callbacks)\n",
    "    evalcallbacks = [\n",
    "        CSVLogger(\"./BCSS-master/files/eval.csv\")\n",
    "    ]\n",
    "\n",
    "    print(\"Evaluating model\\n\")\n",
    "    model.evaluate(test_dataset, steps=test_steps, callbacks=evalcallbacks)\n",
    "    print(\"Evaluating model ... complete\\n\")\n",
    "\n",
    "    for i, (x, y) in tqdm(enumerate(zip(test_x, test_y)), total=len(test_x)):\n",
    "        x = read_image_test(x)\n",
    "        y = read_mask_test(y)\n",
    "        y_pred = model.predict(np.expand_dims(x, axis=0))\n",
    "        #cv2.imwrite(\"./results/\"+str(i)+\".png\", y_pred)\n",
    "        h, w, _ = x.shape\n",
    "        white_line = np.ones((h, 5, 3)) * 255.0\n",
    "\n",
    "        #print(\"Printing sizes\\n\")\n",
    "        #print(mask_parse(y_pred).shape)\n",
    "        #print(mask_parse(y).shape)\n",
    "        # print(x.shape)\n",
    "        # print(myfun(y_pred).shape)\n",
    "        all_images = [\n",
    "            x * 255.0, white_line,\n",
    "            y*255.0, white_line,\n",
    "            myfun(y_pred) * 255.0\n",
    "        ]\n",
    "        image = np.concatenate(all_images, axis=1)\n",
    "        cv2.imwrite(f\"results/{i}.png\", image)\n",
    "    print(type(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59364052",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
